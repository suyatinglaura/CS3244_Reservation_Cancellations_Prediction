{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_with_kfold(X_train, Y_train, X_test, Y_test, models, n_folds=5):\n",
    "    meta_model = LogisticRegression()\n",
    "\n",
    "    meta_X_train = np.zeros((X_train.shape[0], len(models)))\n",
    "    meta_X_test = np.zeros((X_test.shape[0], len(models)))\n",
    "\n",
    "    metrics = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=47)\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "        print(f\"Fold {fold+1}/{n_folds}\")\n",
    "\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        Y_train_fold, Y_val_fold = Y_train.iloc[train_index], Y_train.iloc[val_index]\n",
    "\n",
    "        for i, model in enumerate(models):\n",
    "            model.fit(X_train_fold, Y_train_fold)\n",
    "            meta_X_train[val_index, i] = model.predict_proba(X_val_fold)[:, 1]\n",
    "        for i, (model, name) in enumerate(zip(models, [type(model).__name__ for model in models])):\n",
    "            y_val_pred = model.predict(X_val_fold)\n",
    "            acc = accuracy_score(Y_val_fold, y_val_pred)\n",
    "            prec = precision_score(Y_val_fold, y_val_pred)\n",
    "            rec = recall_score(Y_val_fold, y_val_pred)\n",
    "            f1 = f1_score(Y_val_fold, y_val_pred)\n",
    "            metrics = metrics.append({'Model': name, 'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1 Score': f1}, ignore_index=True)\n",
    "            print(f\"{name} Validation Metrics: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "    meta_model.fit(meta_X_train, Y_train)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        meta_X_test[:, i] = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    y_test_pred = meta_model.predict(meta_X_test)\n",
    "\n",
    "    acc = accuracy_score(Y_test, y_test_pred)\n",
    "    prec = precision_score(Y_test, y_test_pred)\n",
    "    rec = recall_score(Y_test, y_test_pred)\n",
    "    f1 = f1_score(Y_test, y_test_pred)\n",
    "    metrics = metrics.append({'Model': 'Stacked Logistic Regression', 'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1 Score': f1}, ignore_index=True)\n",
    "    print(f\"Stacked Logistic Regression Test Metrics: Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Creative points:\n",
    "1. 2 layers of stacking\n",
    "2. unsupervised learning on predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project Structure Guidelines\n",
    "\n",
    "## File Structure\n",
    "\n",
    "1. **data/**\n",
    "   - `raw/`: Contains the raw, unprocessed data files.\n",
    "   - `cleaned/`: Stores the cleaned and preprocessed data files.\n",
    "   - `processed/`: Holds the final, transformed data files ready for modeling.\n",
    "\n",
    "2. **notebooks/**\n",
    "   - `01_data_exploration.ipynb`: Exploratory data analysis, data visualization, and initial insights.\n",
    "   - `02_data_cleaning.ipynb`: Data cleaning, handling missing values, and other preprocessing steps.\n",
    "   - `03_feature_engineering.ipynb`: Feature engineering, including creating new features, transforming existing features, and feature selection.\n",
    "   - `04_model_training.ipynb`: Model training, hyperparameter tuning, and evaluation.\n",
    "   - `05_model_deployment.ipynb`: Saving the trained model, creating a deployment-ready artifact, and writing inference scripts.\n",
    "\n",
    "3. **src/**\n",
    "   - `utils.py`: Utility functions used across the project, such as data loading, data transformation, and model evaluation.\n",
    "   - `models.py`: Custom model definitions and training/inference functions.\n",
    "\n",
    "4. **requirements.txt**: A file listing the Python dependencies required for the project.\n",
    "5. **README.md**: A detailed project overview, instructions for setup, and usage guidelines.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Data Exploration**: In `01_data_exploration.ipynb`, perform your initial exploratory data analysis (EDA), including data visualization and gaining initial insights about the dataset. Save the cleaned and preprocessed data in the `cleaned/` directory of the `data/` folder.\n",
    "\n",
    "2. **Data Cleaning**: In `02_data_cleaning.ipynb`, handle missing values, remove outliers, and perform other data cleaning tasks. Save the cleaned data in the `cleaned/` directory.\n",
    "\n",
    "3. **Feature Engineering**: In `03_feature_engineering.ipynb`, create new features, transform existing features, and perform feature selection. Save the final, transformed data in the `processed/` directory.\n",
    "\n",
    "4. **Model Training**: In `04_model_training.ipynb`, load the processed data from the `processed/` directory, train your machine learning models, and evaluate their performance.\n",
    "\n",
    "5. **Model Deployment**: In `05_model_deployment.ipynb`, save the trained model, create a deployment-ready artifact, and write inference scripts to use the model in a production environment.\n",
    "\n",
    "Throughout the project, utilize the utility functions in `utils.py` and the custom model definitions in `models.py` to ensure consistency and reusability of your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
